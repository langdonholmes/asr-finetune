{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af974f5a-2f03-45a4-8bb9-317bf85a9bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "from datasets import load_from_disk\n",
    "from evaluate import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "222def0e-1b0a-4d70-b44a-e9570baa6c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\"\n",
    "\n",
    "model_id = \"openai/whisper-large-v3\"\n",
    "\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, low_cpu_mem_usage=True,\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    chunk_length_s=30,\n",
    "    batch_size=1,  # batch size for inference - set based on your device\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5299154-39dd-4d63-8241-5307658976cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dss = {\n",
    "    \"cslu\": load_from_disk(\"../data/cslu_kids.ds\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6b96a09-b79d-45ba-b533-1c66204cbe2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bn> a b c d e f g <br> h i j k<ln> l m n o p<ln> <br> q r s t u v w x y and z <bn> <pau> my<bn> family<bn> <bn> she<bn> went<bn> to<bn> go<bn> pick<bn> up<bn> my<bn> little<bn> sister<bn> and<bn> she's gonna<bn> <br> come<bn> tomorrow she's gonna come at eleven <pau> yeah <pau> <bn> okay <bn> clean my room <bn> and<bn> then<bn> when<bn> i'm<bn> done<bn> i<bn> get<bn> to<bn> play<bn> with<bn> my<bn> friend<bn> <pau> brittney we go over to her house and we play barbies <pau> and <br> we uhm <pau> we ride our bikes after we're done and then we eat some ice cream <pau> i have four sisters <pau> <bs> one's fifteen <bn> th* four* thirteen <br> and ten and one's five <pau> yeah <pau> <bn> they're nice and they let me <br> uhm watch tv<ln> in their room <bs> and uhm <br> <pau> and<bn> <br> she<bn> when sometimes<ln> when i <br> do a little bit of chores <br> she gives me a dollar\n",
      "{'text': \" A, B, C, D, E, F, G, H, I, J, K, L, M, N, O, P, Q, R, S, T, U, V, W, X, Y, and Z. My family. She went to go pick up my little sister. She's gonna come tomorrow. She's gonna come at 11. Yeah. Okay. Clean my room. And then when I'm done, I get to play with my friend, Brittany. We go over to her house and we play Barbies. And we, um, we ride our bikes after we're done and then we eat some ice cream. I have four sisters. One's 15, 13, and 10, and one's 5. Yeah. They're nice. And they let me watch TV in their room. And she, when sometimes when I do a little bit of chores, she gives me a dollar.\"}\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "sample = dss[\"cslu\"][0][\"audio\"]\n",
    "\n",
    "result = pipe(sample)\n",
    "print(dss[\"cslu\"][0][\"sentence\"])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65961980-2890-4bb0-9df3-f01669a670a1",
   "metadata": {},
   "source": [
    "# Run on all Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdea92fc-909d-4c69-b014-26b086571e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pipe(dss[\"cslu\"][\"audio\"])\n",
    "print(results[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eba6ac97-e7dc-45e1-8c89-bf03f2a3afd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from text2digits import text2digits\n",
    "import string\n",
    "\n",
    "t2d = text2digits.Text2Digits()\n",
    "punctuation_remover = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "def normalize_transcript(text):\n",
    "    # The original transcript has annotations, for example a pause is <pau>\n",
    "    # Remove tags in angle brackets\n",
    "    text = re.sub(r'<[^>]*>', '', text)\n",
    "    \n",
    "    # These are \"false starts\" in the original transcript, for example th*\n",
    "    # These are ignored by ASR\n",
    "    # Remove words that end with asterisks (e.g., th*)\n",
    "    text = re.sub(r'\\S*\\*', '', text)\n",
    "\n",
    "    # Remove all punctuation\n",
    "    text = text.translate(punctuation_remover)\n",
    "\n",
    "    # Clean up excess spaces in the original transcript or resulting from above operations\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    # Convert number representations, e.g., \"thirteen\" to \"13\"\n",
    "    # This is imperfect (does not know when \"one\" is a pronoun vs. a number)\n",
    "    # But we apply the same normalization to both samples, so works fine for Word Error Rate\n",
    "    try:\n",
    "        normalized_text = t2d.convert(text)\n",
    "    except:\n",
    "        print(text)\n",
    "    return normalized_text.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "73e7f201-c0ed-49a2-9a71-39405cdbd72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20958586984480837\n"
     ]
    }
   ],
   "source": [
    "wer = load(\"wer\")\n",
    "predictions = [normalize_transcript(d[\"text\"]) for d in results]\n",
    "references = [normalize_transcript(text) for text in dss[\"cslu\"][\"sentence\"]]\n",
    "wer_score = wer.compute(predictions=predictions, references=references)\n",
    "print(wer_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hf]",
   "language": "python",
   "name": "conda-env-hf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
