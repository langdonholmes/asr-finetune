{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af974f5a-2f03-45a4-8bb9-317bf85a9bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import re\n",
    "import jiwer\n",
    "from transformers.models.whisper.english_normalizer import BasicTextNormalizer\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "from datasets import load_from_disk\n",
    "from evaluate import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "222def0e-1b0a-4d70-b44a-e9570baa6c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\"\n",
    "\n",
    "model_id = \"openai/whisper-large-v3\"\n",
    "\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, low_cpu_mem_usage=True,\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    chunk_length_s=30,\n",
    "    batch_size=1,  # batch size for inference - set based on your device\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5299154-39dd-4d63-8241-5307658976cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dss = {\n",
    "    \"cslu\": load_from_disk(\"../data/cslu_kids.ds\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6b96a09-b79d-45ba-b533-1c66204cbe2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/conda_envs/hf/lib/python3.11/site-packages/transformers/models/whisper/generation_whisper.py:573: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bn> a b c d e f g <br> h i j k<ln> l m n o p<ln> <br> q r s t u v w x y and z <bn> <pau> my<bn> family<bn> <bn> she<bn> went<bn> to<bn> go<bn> pick<bn> up<bn> my<bn> little<bn> sister<bn> and<bn> she's gonna<bn> <br> come<bn> tomorrow she's gonna come at eleven <pau> yeah <pau> <bn> okay <bn> clean my room <bn> and<bn> then<bn> when<bn> i'm<bn> done<bn> i<bn> get<bn> to<bn> play<bn> with<bn> my<bn> friend<bn> <pau> brittney we go over to her house and we play barbies <pau> and <br> we uhm <pau> we ride our bikes after we're done and then we eat some ice cream <pau> i have four sisters <pau> <bs> one's fifteen <bn> th* four* thirteen <br> and ten and one's five <pau> yeah <pau> <bn> they're nice and they let me <br> uhm watch tv<ln> in their room <bs> and uhm <br> <pau> and<bn> <br> she<bn> when sometimes<ln> when i <br> do a little bit of chores <br> she gives me a dollar\n",
      "{'text': \" A, B, C, D, E, F, G, H, I, J, K, L, M, N, O, P, Q, R, S, T, U, V, W, X, Y, and Z. My family. She went to go pick up my little sister. She's gonna come tomorrow. She's gonna come at 11. Yeah. Okay. Clean my room. And then when I'm done, I get to play with my friend, Brittany. We go over to her house and we play Barbies. And we, um, we ride our bikes after we're done and then we eat some ice cream. I have four sisters. One's 15, 13, and 10, and one's 5. Yeah. They're nice. And they let me watch TV in their room. And she, when sometimes when I do a little bit of chores, she gives me a dollar.\"}\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "sample = dss[\"cslu\"][0][\"audio\"]\n",
    "\n",
    "result = pipe(sample)\n",
    "print(dss[\"cslu\"][0][\"sentence\"])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65961980-2890-4bb0-9df3-f01669a670a1",
   "metadata": {},
   "source": [
    "# Run on all Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdea92fc-909d-4c69-b014-26b086571e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pipe(dss[\"cslu\"][\"audio\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eba6ac97-e7dc-45e1-8c89-bf03f2a3afd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from text2digits import text2digits\n",
    "import string\n",
    "\n",
    "t2d = text2digits.Text2Digits()\n",
    "punctuation_remover = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "def normalize_transcript(text):\n",
    "    # The original transcript has annotations, for example a pause is <pau>\n",
    "    # Remove tags in angle brackets\n",
    "    text = re.sub(r'<[^>]*>', '', text)\n",
    "    \n",
    "    # These are \"false starts\" in the original transcript, for example th*\n",
    "    # These are ignored by ASR\n",
    "    # Remove words that end with asterisks (e.g., th*)\n",
    "    text = re.sub(r'\\S*\\*', '', text)\n",
    "\n",
    "    # Remove all punctuation\n",
    "    text = text.translate(punctuation_remover)\n",
    "\n",
    "    # Clean up excess spaces in the original transcript or resulting from above operations\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    # Convert number representations, e.g., \"thirteen\" to \"13\"\n",
    "    # This is imperfect (does not know when \"one\" is a pronoun vs. a number)\n",
    "    # But we apply the same normalization to both samples, so works fine for Word Error Rate\n",
    "    try:\n",
    "        normalized_text = t2d.convert(text)\n",
    "    except:\n",
    "        print(text)\n",
    "    return normalized_text.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "73e7f201-c0ed-49a2-9a71-39405cdbd72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20958586984480837\n"
     ]
    }
   ],
   "source": [
    "wer = load(\"wer\")\n",
    "predictions = [normalize_transcript(d[\"text\"]) for d in results]\n",
    "references = [normalize_transcript(text) for text in dss[\"cslu\"][\"sentence\"]]\n",
    "wer_score = wer.compute(predictions=predictions, references=references)\n",
    "print(wer_score) # 0.20958586984480837 on 07-08-25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32b5d10f-9607-4f5b-8df1-e3dd07e96fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = BasicTextNormalizer()\n",
    "\n",
    "def normalize_transcript(text):\n",
    "    # The original transcript has annotations, for example a pause is <pau>\n",
    "    # Remove tags in angle brackets\n",
    "    text = re.sub(r'<[^>]*>', '', text)\n",
    "    \n",
    "    # These are \"false starts\" in the original transcript, for example th*\n",
    "    # These are ignored by ASR\n",
    "    # Remove words that end with asterisks (e.g., th*)\n",
    "    text = re.sub(r'\\S*\\*', '', text)\n",
    "\n",
    "    # Apply Whisper's English normalizer\n",
    "    normalized_text = normalizer(text)\n",
    "\n",
    "    return normalized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08501fcb-ae32-4884-8b42-17c25af63a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'wer': 0.2082938074963048}\n"
     ]
    }
   ],
   "source": [
    "def weighted_wer(ref: list[str], pred: list[str]):\n",
    "    # Normalize both predictions and references\n",
    "    pred_normalized = [normalize_transcript(text) for text in pred]\n",
    "    label_normalized = [normalize_transcript(text) for text in ref]\n",
    "    \n",
    "    total_errors = 0\n",
    "    total_words = 0\n",
    "    \n",
    "    for pred_text, ref_text in zip(pred_normalized, label_normalized):\n",
    "        ref_words = ref_text.split()\n",
    "            \n",
    "        # Compute WER for this sample\n",
    "        sample_wer = jiwer.wer(ref_text, pred_text)\n",
    "        \n",
    "        # Accumulate weighted errors\n",
    "        sample_errors = sample_wer * len(ref_words)\n",
    "        total_errors += sample_errors\n",
    "        total_words += len(ref_words)\n",
    "    \n",
    "    weighted_wer = total_errors / total_words if total_words > 0 else 0.0\n",
    "    \n",
    "    return {\"wer\": weighted_wer}\n",
    "\n",
    "predictions = [d[\"text\"] for d in results]\n",
    "references = dss[\"cslu\"][\"sentence\"]\n",
    "wer_score = weighted_wer(references, predictions)\n",
    "print(wer_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hf]",
   "language": "python",
   "name": "conda-env-hf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
