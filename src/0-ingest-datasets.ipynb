{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b8e4aaf-fef9-4034-abba-970133ee8bec",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "This notebook ingests data from multiple sources and formats and coverts it to a standard HuggingFace dataset format.\n",
    "\n",
    "All datasets will have \"sentence\" and \"audio\" features. Different datasets may contain additional metadata information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f19e7bd4-5bce-42cd-b4b6-cb907185215c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "from datasets import Dataset, Features, Audio, Value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ab282f-99b5-43f7-a1f0-b9a54eb0e2e0",
   "metadata": {},
   "source": [
    "## CSLU Kids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a81b6d86-0228-40ab-a2fe-84acebd779a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1101 matching audio-transcript pairs\n",
      "Successfully processed 1101 pairs\n",
      "Building dataset...\n",
      "Casting dataset column...\n",
      "\n",
      "Dataset created successfully!\n",
      "Number of samples: 1101\n",
      "Features: {'audio': Audio(sampling_rate=None, mono=True, decode=True, id=None), 'sentence': Value(dtype='string', id=None)}\n",
      "\n",
      "First sample:\n",
      "Audio path: ../data/cslu_kids/speech/spontaneous/02/0/ksd14/ksd14xx0.wav\n",
      "Sentence: <bn> a b c d e f g <br> h i j k<ln> l m n o p<ln> <br> q r s t u v w x y and z <bn> <pau> my<bn> fam...\n"
     ]
    }
   ],
   "source": [
    "# Path to your decompressed directory\n",
    "cslu_dir_path = \"../data/cslu_kids\"  # Adjust this to your decompressed directory path\n",
    "\n",
    "def read_transcript(transcript_path: str) -> str:\n",
    "    \"\"\"Read transcript content from a file path.\"\"\"\n",
    "    try:\n",
    "        with open(transcript_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read().strip()\n",
    "            return content\n",
    "    except Exception as e:\n",
    "        print(f\"Could not read transcript {transcript_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def extract_and_match_files(dir_path: str) -> Dataset:\n",
    "    \"\"\"\n",
    "    Find matching audio and transcript files in a directory structure.\n",
    "    \n",
    "    Args:\n",
    "        dir_path: Path to the decompressed directory\n",
    "        \n",
    "    Returns:\n",
    "        Hugging Face Dataset with 'audio' and 'sentence' features\n",
    "    \"\"\"\n",
    "    audio_transcript_pairs = []\n",
    "    \n",
    "    # Walk through the directory structure\n",
    "    audio_files = {}\n",
    "    transcript_files = {}\n",
    "    \n",
    "    for root, dirs, files in os.walk(dir_path):\n",
    "        path_parts = Path(root).parts\n",
    "        \n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            file_id = Path(file).stem\n",
    "            \n",
    "            # Check if it's an audio file in speech directory\n",
    "            if 'speech' in path_parts and file.endswith('.wav'):\n",
    "                audio_files[file_id] = file_path\n",
    "            \n",
    "            # Check if it's a transcript file in trans directory\n",
    "            elif 'trans' in path_parts and file.endswith('.txt'):\n",
    "                transcript_files[file_id] = file_path\n",
    "    \n",
    "    # Find matching pairs\n",
    "    common_ids = set(audio_files.keys()) & set(transcript_files.keys())\n",
    "    print(f\"Found {len(common_ids)} matching audio-transcript pairs\")\n",
    "    \n",
    "    # Build lists of matched audio paths and sentences\n",
    "    audio_paths = []\n",
    "    sentences = []\n",
    "    \n",
    "    for file_id in common_ids:\n",
    "        audio_path = audio_files[file_id]\n",
    "        transcript_path = transcript_files[file_id]\n",
    "        \n",
    "        # Read the transcript\n",
    "        sentence = read_transcript(transcript_path)\n",
    "        \n",
    "        # Only add if we successfully read the transcript\n",
    "        if sentence:\n",
    "            audio_paths.append(audio_path)\n",
    "            sentences.append(sentence)\n",
    "    \n",
    "    print(f\"Successfully processed {len(audio_paths)} pairs\")\n",
    "    print(\"Building dataset...\")\n",
    "    \n",
    "    # Create dataset with correct feature name 'sentence' instead of 'sentences'\n",
    "    ds = Dataset.from_dict({\n",
    "        \"audio\": audio_paths,\n",
    "        \"sentence\": sentences  # Changed from 'sentences' to 'sentence'\n",
    "    })\n",
    "    \n",
    "    print(\"Casting dataset column...\")\n",
    "    ds = ds.cast_column(\"audio\", Audio())\n",
    "    \n",
    "    return ds\n",
    "\n",
    "# Create the dataset\n",
    "cslu_kids = extract_and_match_files(cslu_dir_path)\n",
    "\n",
    "# Print dataset info\n",
    "print(f\"\\nDataset created successfully!\")\n",
    "print(f\"Number of samples: {len(cslu_kids)}\")\n",
    "print(f\"Features: {cslu_kids.features}\")\n",
    "\n",
    "# Show first sample info\n",
    "if len(cslu_kids) > 0:\n",
    "    first_sample = cslu_kids[0]\n",
    "    print(f\"\\nFirst sample:\")\n",
    "    print(f\"Audio path: {first_sample['audio']['path']}\")\n",
    "    print(f\"Sentence: {first_sample['sentence'][:100]}...\")  # First 100 chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "029573a0-5b49-47a5-b6dc-2b6f8c52e889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2a70509456549939f5aa43109880da6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/8 shards):   0%|          | 0/1101 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset saved to: ../data/cslu_kids.ds\n"
     ]
    }
   ],
   "source": [
    "# Save dataset\n",
    "output_path = \"../data/cslu_kids.ds\"\n",
    "cslu_kids.save_to_disk(output_path)\n",
    "print(f\"\\nDataset saved to: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hf]",
   "language": "python",
   "name": "conda-env-hf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
