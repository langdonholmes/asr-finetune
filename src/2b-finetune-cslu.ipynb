{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af974f5a-2f03-45a4-8bb9-317bf85a9bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import (\n",
    "    AutoModelForSpeechSeq2Seq,\n",
    "    AutoProcessor,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer\n",
    ")\n",
    "import evaluate\n",
    "from datasets import Dataset, DatasetDict, load_from_disk\n",
    "\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "import re\n",
    "import string\n",
    "\n",
    "from text2digits import text2digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "222def0e-1b0a-4d70-b44a-e9570baa6c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\"\n",
    "torch_dtype = torch.float32\n",
    "\n",
    "model_id = \"openai/whisper-large-v3\"\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "# Configure generation\n",
    "model.generation_config.language = \"english\"\n",
    "model.generation_config.task = \"transcribe\"\n",
    "model.generation_config.forced_decoder_ids = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5299154-39dd-4d63-8241-5307658976cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cslu = load_from_disk(\"../data/cslu_kids.ds\").train_test_split(test_size=0.2, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55d00cdb-1b10-4613-9a5c-c47bc84ab1e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['audio', 'sentence'],\n",
       "        num_rows: 880\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['audio', 'sentence'],\n",
       "        num_rows: 221\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cslu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b4c011cc-a01f-446e-a503-b361e19b28d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b c d e <pau> h i l m n o p<ln> q r s<ln> t<ln> u v w x<ln> y z <br> i went to my brother's friend and then we went to<ln> burger king and then we went to the park<ln> and we uhm came to a house uhm i went down the<ln> slide mom like <bs> my mom's name's caitlin <br> and my dad's name's miguel and my <br> big brother's<ln> name's freddie<ln> and my little brother's eric<ln> uhm my little brother's four years old and my big brother's<ln> sixteen years old and <br> i uhm i don't fight with them i always play<ln> with them and share<ln> stuff with them cada<nitl> hand and i mean <br> cada<nitl> face hay<nitl> un<nitl> neve<nitl> se<nitl> perrito<nitl> que<nitl> se<nitl> hay<nitl> muerto<nitl> there was there was a dog that <br> uhm he died <laugh>\n",
      "<br> a b c d e f g h i j k<ln> l m n o p<ln> q r s t u <br> v w x y z <br> okay <br> uhm i have a room <br> that i share with my brother <br> and both of us have two of he exactly same stereos but mine is a little bit taller<ln> <br> and then in our living room we have a very tall<ln> stereo <br> that has <br> a lot of buttons <br> and it has a c d player <br> and a tape recor[der]* i mean a tape player <br> and in the bathroom we have a shower<ln> and a sink and a toilet and <bn> toothpaste<ln> and tooth brushes <br> and in my mom's bedroom <ns> they have a big bed and no stereo <br> but they do have a t v <br> and <br> on mother's day i ga[ve]* i fixed<ln> my mom dinner but not by myself i fixed it<ln> with my dad <br> and my brothers <br>\n",
      "a b c<ln> d e f g h i j k<ln> l m n o p <br> q<ln> r s<ln> t u v w x y and z okay i went to my friend's house <br> and we went on a bike ride and we went swimming<ln> and shopping and <br> she got shoes for a wedding and we had a really good time we ate out one night that's really fun we ate at uhm chuck wagon <br> and they had* they got a new dog so we had fun playing with it mm they had uhm a b[lack]* a new black lab uhm i'm gonna go to a place<ln> called<ln> diamond lake and my family goes there every year and we play like on a boat and we camp there for a while <ln> it's really fun\n",
      "a b c d e f g <br> h i j k l m n o p <br> q r s t<ln> u v <br> w x y and z hi my name is nicholas reynolds <br> i don't really know what to talk about <laugh> my favorite sport is soccer <br> we had a great team<ln> last<ln> year uhm i have four people in my f* family <laugh> my dad's roger my mom is kim and my sister is nelly my sister is a real brat <br> <laugh> i have a cat named shadow because it shadows me like a dog <br> uhm i play the piano and <br> i go to school at tom mccall my<ln> teacher<ln> is mister shepherd we have thirty one people in our class <bn> right now i'm sitting at the peace club room talking <br> to a computer <br> <bn> there are a bunch of chairs in this room there is computers and there is mouse or mice or whatever <laugh> <br> i have a co[mputer]* computer at my home my friend has a computer\n",
      "a b<ln> c d e f g<ln> h i j k l m n o p<ln> q r s t u v<bn> w x<ln> y<ln> and z i like to go camping because <br> because like me and my brother <br> get to roast marsmallows and stay up as late as we want <br> grants pass bend california and everywhere else <bs> california <br> in california it's really hot and it's good* it's really nice there <br> it doesn't rain that much <br> in my family i have three* three brothers one sister <br> my oldest brother is twenty three <br> my middle bro[ther]* my second oldest is twenty two <br> or twenty one and my youngest is twen[ty]* my youngest <br> is <ns> eight and my older sister is seventeen <bs> no <br> my sister sometimes punches me <ns> my brother kicks me <br> and i get on with my two older brothers but not that well <bs>\n",
      "<bn> a b c d <br> e f g h i j k l m n o p <br> q r s t u v <br> w x y and z <bn> <pau> they are good basketball players <pau> <bs> play with my friends uhm todd <pau> <br> yeah he's really nice <br> and he <br> has <bs> and he has a family <bn> it's messy and like <br> <pau> <bn> i have a bed and a desk and uhm bookshelf and <bn> a sh* a dresser and a shelf <fp> they <bn> have <bn> there michael jordan poster and a dalmatian poster and <bs>\n",
      "<br> a b c<ln> d e f g <br> h<ln> i j k l m n o p q r x t u v w x y and z <br> i don't know <br> uhm <br> i play volleyball and basketball <ns> uhm i play <br> center and server <bn> <bs> *titanic<ln> <br> uhm it's with leonardo di caprio and kate winslett and leonardo di caprio dies and the titanic<ln> sinks that's all <br> <bs> uh uhm that <br> if they* if the captain would've turned a little bit left it wouldn't have sunk and if they would've listened to<ln> the message<ln> thingies that<ln> they wouldn't have sunk either okay <br> my oldest brother is nice and uhm <br> he is fifteen<ln> he is a sophomore in high school <br> and my little brother jason <br> is eleven <br> and his birthday is on december twenty fourth <br> and jessica's seven <br> and she is good in gymnastics <br> and lisa's<ln> three and she talks a lot\n",
      "*alright <br> a b<ln> c d e f<ln> g <br> h i j k <br>l m n o p<ln> <br> q r s t u v <br> w x y z <pau> uh i got in there and <ns> sat down and the band played and uhm <ls> and then they introduced all the different sports teams and they had some contest thing where you spin around with a baseball bat and try to hit the ball and then it was over from each class <bs> <pau> it was like uhm they spin around five times and there's a baseball on one of the tee<ln> things <br> and they tried to hit it and then they had to run around the bases and do different stuff it was* it was timed  and then the seniors won\n",
      "a b c d e f g h i j k <pau> j k l m n o p q r s <br> t u v w <br> x y and z <bn> we had cake and <pau> we opened presents and we did games <bn> <pau> we we first we did a pinata <pau> <bs> at this bowling one <pau> there's like these bunnies that and we like <br> roll the ball<bn> <pau> it's<bn> a <pau> freeway one <pau> you hit the<long> pinata <pau> <bs> no<bn> <bs> it was my party <pau> <bn> and then some few kids left\n",
      "a b c d e f g <br> h i j k l m n o p q r s t<ln> u v w x y and z uhm i went so<ln> far to play basketballs<ln> with my dad<ln> and my cousins <br> and uhm after that we came home and ate dinner and then on sunday we went swimming almost all day<ln> we went to<ln> forest grove swimming pool pool and that we just went like for two hours <br> and then we went to the uhm to<ln> the beach but not just for uh like five hours and we didn't<ln> stay that much there because he had to come home and plus my d[ad]*<ln> my dad had to go work on mon[day]* <pau> okay uhm uhm uhm uh my family we live in a apartment that's me my brother my little sister my mom my dad <br> uhm almost every time<ln> when i come home <br> my uhm i have to like give something to my sister to<ln> eat because my mom is usually doing something else <br> and uhm my brother he comes home with me too<bn> so we ride the same bus <br> and he almost stays almost all the day<ln> after school outside playing with his friends<ln> <br> okay on* <br> on on a saturday we went to buy <br> a parakeet <br> and so we kept it there hanging <br> we only kept it two<ln> days because when* when my sister w[as]* was* got mad she was throwing cars and a lot of toys everywhere <br> and then she hit it right in the head<ln>\n"
     ]
    }
   ],
   "source": [
    "for sample in cslu[\"train\"].select(range(10)):\n",
    "    print(sample[\"sentence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eba6ac97-e7dc-45e1-8c89-bf03f2a3afd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f09a96f55cbb427c9edd619a040b5f8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c820e82dfe59451387031b21983a85cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t2d = text2digits.Text2Digits()\n",
    "punctuation_remover = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "def normalize_transcript(text):\n",
    "    # The original transcript has annotations, for example a pause is <pau>\n",
    "    # Remove tags in angle brackets\n",
    "    text = re.sub(r'<[^>]*>', '', text)\n",
    "    \n",
    "    # These are \"false starts\" in the original transcript, for example th*\n",
    "    # These are ignored by ASR\n",
    "    # Remove words that end with asterisks (e.g., th*)\n",
    "    text = re.sub(r'\\S*\\*', '', text)\n",
    "\n",
    "    # Remove all punctuation\n",
    "    text = text.translate(punctuation_remover)\n",
    "\n",
    "    # Clean up excess spaces in the original transcript or resulting from above operations\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    # Convert number representations, e.g., \"thirteen\" to \"13\"\n",
    "    # This is imperfect (does not know when \"one\" is a pronoun vs. a number)\n",
    "    # But we apply the same normalization to both samples, so works fine for Word Error Rate\n",
    "    try:\n",
    "        normalized_text = t2d.convert(text)\n",
    "    except:\n",
    "        print(text)\n",
    "    return normalized_text.strip().lower()\n",
    "\n",
    "def prepare_dataset(batch):\n",
    "    # Load audio\n",
    "    audio = batch[\"audio\"]\n",
    "    \n",
    "    # Check if audio is longer than 30 seconds\n",
    "    max_audio_length = 30 * 16000  # 30 seconds at 16kHz\n",
    "    \n",
    "    if len(audio[\"array\"]) > max_audio_length:\n",
    "        # Skip samples longer than 30 seconds to avoid mismatch\n",
    "        # Alternative: you could return None and filter these out\n",
    "        return None\n",
    "    \n",
    "    # Compute log-Mel input features (no truncation, just padding)\n",
    "    batch[\"input_features\"] = processor.feature_extractor(\n",
    "        audio[\"array\"], \n",
    "        sampling_rate=audio[\"sampling_rate\"],\n",
    "        padding=True\n",
    "    ).input_features[0]\n",
    "    \n",
    "    # Normalize and encode target text (no truncation)\n",
    "    normalized_text = normalize_transcript(batch[\"sentence\"])\n",
    "    \n",
    "    # Check if text is too long (safety check)\n",
    "    tokens = processor.tokenizer(normalized_text).input_ids\n",
    "    if len(tokens) > 448:\n",
    "        # Skip very long transcripts\n",
    "        return None\n",
    "    \n",
    "    batch[\"labels\"] = tokens\n",
    "    return batch\n",
    "\n",
    "\n",
    "def filter_long_samples(batch):\n",
    "    # Remove samples longer than 30 seconds\n",
    "    return len(batch[\"audio\"][\"array\"]) <= 30 * 16000\n",
    "\n",
    "\n",
    "cslu_processed = cslu.filter(filter_long_samples).map(\n",
    "    prepare_dataset, \n",
    "    remove_columns=cslu.column_names[\"train\"], \n",
    "    num_proc=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9e1f56f2-9a1b-463a-8a29-c74a1eb69223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_features', 'labels'],\n",
       "        num_rows: 6\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_features', 'labels'],\n",
       "        num_rows: 3\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cslu_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c89eff1e-140d-43ad-a4b9-c702a2bc7778",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "    decoder_start_token_id: int\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # Split inputs and labels\n",
    "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "        \n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "        \n",
    "        # Replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "        \n",
    "        batch[\"labels\"] = labels\n",
    "        return batch\n",
    "\n",
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(\n",
    "    processor=processor,\n",
    "    decoder_start_token_id=model.config.decoder_start_token_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5f6550b7-a019-4393-9a0e-8352d79d394b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wer = evaluate.load(\"wer\")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    pred_ids = pred.predictions\n",
    "    label_ids = pred.label_ids\n",
    "    \n",
    "    # Replace -100 with pad token\n",
    "    label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "    \n",
    "    # Decode predictions and labels\n",
    "    pred_str = processor.tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str = processor.tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "    \n",
    "    # Normalize both predictions and references\n",
    "    pred_normalized = [normalize_transcript(text) for text in pred_str]\n",
    "    label_normalized = [normalize_transcript(text) for text in label_str]\n",
    "    \n",
    "    # Compute WER\n",
    "    wer_score = wer.compute(predictions=pred_normalized, references=label_normalized)\n",
    "    \n",
    "    return {\"wer\": wer_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "06954565-b7cc-4bf3-8a47-3d3b5543e422",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"../bin/whisper-cslu-kids\",\n",
    "    per_device_train_batch_size=8,  # Smaller batch size for kids dataset\n",
    "    gradient_accumulation_steps=2,\n",
    "    learning_rate=1e-5,\n",
    "    warmup_steps=100,\n",
    "    max_steps=1000,  # Fewer steps for proof of concept\n",
    "    gradient_checkpointing=True,\n",
    "    fp16=True,\n",
    "    eval_strategy=\"steps\",\n",
    "    per_device_eval_batch_size=4,\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=225,\n",
    "    save_steps=250,\n",
    "    eval_steps=250,\n",
    "    logging_steps=50,\n",
    "    report_to=[],  # Disable logging for simplicity\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"wer\",\n",
    "    greater_is_better=False,\n",
    "    push_to_hub=False,  # Set to True if you want to upload\n",
    ")\n",
    "\n",
    "# 7. Create trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    train_dataset=cslu_processed[\"train\"],\n",
    "    eval_dataset=cslu_processed[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    processing_class=processor.feature_extractor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e1f4e339-3c2f-4a0f-b6b8-ad6ec32252ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='85' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  85/1000 03:03 < 33:45, 0.45 it/s, Epoch 84/1000]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 8. Start training\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting training...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/conda_envs/hf/lib/python3.11/site-packages/transformers/trainer.py:2241\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2239\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2242\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2246\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/conda_envs/hf/lib/python3.11/site-packages/transformers/trainer.py:2500\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2498\u001b[0m update_step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2499\u001b[0m num_batches \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps \u001b[38;5;28;01mif\u001b[39;00m update_step \u001b[38;5;241m!=\u001b[39m (total_updates \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m remainder\n\u001b[0;32m-> 2500\u001b[0m batch_samples, num_items_in_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_batch_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_batches\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2501\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(batch_samples):\n\u001b[1;32m   2502\u001b[0m     step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/conda_envs/hf/lib/python3.11/site-packages/transformers/trainer.py:5180\u001b[0m, in \u001b[0;36mTrainer.get_batch_samples\u001b[0;34m(self, epoch_iterator, num_batches)\u001b[0m\n\u001b[1;32m   5178\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_batches):\n\u001b[1;32m   5179\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 5180\u001b[0m         batch_samples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mnext\u001b[39m(epoch_iterator)]\n\u001b[1;32m   5181\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m   5182\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/conda_envs/hf/lib/python3.11/site-packages/accelerate/data_loader.py:564\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;66;03m# We iterate one batch ahead to check when we are at the end\u001b[39;00m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 564\u001b[0m     current_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(dataloader_iter)\n\u001b[1;32m    565\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    566\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n",
      "File \u001b[0;32m~/conda_envs/hf/lib/python3.11/site-packages/torch/utils/data/dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    714\u001b[0m ):\n",
      "File \u001b[0;32m~/conda_envs/hf/lib/python3.11/site-packages/torch/utils/data/dataloader.py:764\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    763\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 764\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    766\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/conda_envs/hf/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:50\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[0;32m~/conda_envs/hf/lib/python3.11/site-packages/datasets/arrow_dataset.py:2786\u001b[0m, in \u001b[0;36mDataset.__getitems__\u001b[0;34m(self, keys)\u001b[0m\n\u001b[1;32m   2784\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitems__\u001b[39m(\u001b[38;5;28mself\u001b[39m, keys: List) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List:\n\u001b[1;32m   2785\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Can be used to get a batch using a list of integers indices.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2786\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2787\u001b[0m     n_examples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch[\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(batch))])\n\u001b[1;32m   2788\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [{col: array[i] \u001b[38;5;28;01mfor\u001b[39;00m col, array \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems()} \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_examples)]\n",
      "File \u001b[0;32m~/conda_envs/hf/lib/python3.11/site-packages/datasets/arrow_dataset.py:2782\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2780\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):  \u001b[38;5;66;03m# noqa: F811\u001b[39;00m\n\u001b[1;32m   2781\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2782\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/conda_envs/hf/lib/python3.11/site-packages/datasets/arrow_dataset.py:2767\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[0;34m(self, key, **kwargs)\u001b[0m\n\u001b[1;32m   2765\u001b[0m formatter \u001b[38;5;241m=\u001b[39m get_formatter(format_type, features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mfeatures, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_kwargs)\n\u001b[1;32m   2766\u001b[0m pa_subtable \u001b[38;5;241m=\u001b[39m query_table(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data, key, indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indices)\n\u001b[0;32m-> 2767\u001b[0m formatted_output \u001b[38;5;241m=\u001b[39m \u001b[43mformat_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2768\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpa_subtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformat_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformat_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_all_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_all_columns\u001b[49m\n\u001b[1;32m   2769\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2770\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m formatted_output\n",
      "File \u001b[0;32m~/conda_envs/hf/lib/python3.11/site-packages/datasets/formatting/formatting.py:658\u001b[0m, in \u001b[0;36mformat_table\u001b[0;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[1;32m    656\u001b[0m python_formatter \u001b[38;5;241m=\u001b[39m PythonFormatter(features\u001b[38;5;241m=\u001b[39mformatter\u001b[38;5;241m.\u001b[39mfeatures)\n\u001b[1;32m    657\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m format_columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 658\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    660\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m format_columns:\n",
      "File \u001b[0;32m~/conda_envs/hf/lib/python3.11/site-packages/datasets/formatting/formatting.py:415\u001b[0m, in \u001b[0;36mFormatter.__call__\u001b[0;34m(self, pa_table, query_type)\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_column(pa_table)\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 415\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/conda_envs/hf/lib/python3.11/site-packages/datasets/formatting/formatting.py:471\u001b[0m, in \u001b[0;36mPythonFormatter.format_batch\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlazy:\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m LazyBatch(pa_table, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 471\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpython_arrow_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    472\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_features_decoder\u001b[38;5;241m.\u001b[39mdecode_batch(batch)\n\u001b[1;32m    473\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m batch\n",
      "File \u001b[0;32m~/conda_envs/hf/lib/python3.11/site-packages/datasets/formatting/formatting.py:151\u001b[0m, in \u001b[0;36mPythonArrowExtractor.extract_batch\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_batch\u001b[39m(\u001b[38;5;28mself\u001b[39m, pa_table: pa\u001b[38;5;241m.\u001b[39mTable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[0;32m--> 151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpa_table\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_pydict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 8. Start training\n",
    "print(\"Starting training...\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984a9576-27fe-442d-8f26-f9b32e8d1001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Evaluate final model\n",
    "print(\"Evaluating final model...\")\n",
    "final_results = trainer.evaluate()\n",
    "print(f\"Final WER: {final_results['eval_wer']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd2f70e-6e49-40e8-bfe2-a5cdf315e276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Test on a few samples\n",
    "print(\"\\nTesting on sample predictions:\")\n",
    "test_samples = cslu_processed[\"test\"].select(range(3))\n",
    "predictions = trainer.predict(test_samples)\n",
    "\n",
    "pred_ids = predictions.predictions\n",
    "pred_str = processor.tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "\n",
    "for i, (pred, label) in enumerate(zip(pred_str, test_samples[\"labels\"])):\n",
    "    label_str = processor.tokenizer.decode(label, skip_special_tokens=True)\n",
    "    print(f\"\\nSample {i+1}:\")\n",
    "    print(f\"Prediction: {normalize_transcript(pred)}\")\n",
    "    print(f\"Reference:  {normalize_transcript(label_str)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hf]",
   "language": "python",
   "name": "conda-env-hf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
