{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af974f5a-2f03-45a4-8bb9-317bf85a9bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import re\n",
    "import jiwer\n",
    "from transformers.models.whisper.english_normalizer import BasicTextNormalizer\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "from datasets import load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "222def0e-1b0a-4d70-b44a-e9570baa6c6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3b746a1b9d24472a409c718d444db97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\"\n",
    "\n",
    "model_id = \"../bin/whisper-cslu-kids\"\n",
    "tokenizer_id = \"openai/whisper-large-v3\"\n",
    "\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id,\n",
    "    low_cpu_mem_usage=True,\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(tokenizer_id)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    chunk_length_s=30,\n",
    "    batch_size=1,  # batch size for inference - set based on your device\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5299154-39dd-4d63-8241-5307658976cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dss = {\n",
    "    \"cslu\": load_from_disk(\"../data/cslu_kids.ds\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6b96a09-b79d-45ba-b533-1c66204cbe2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/conda_envs/hf/lib/python3.11/site-packages/transformers/models/whisper/generation_whisper.py:573: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bn> a b c d e f g <br> h i j k<ln> l m n o p<ln> <br> q r s t u v w x y and z <bn> <pau> my<bn> family<bn> <bn> she<bn> went<bn> to<bn> go<bn> pick<bn> up<bn> my<bn> little<bn> sister<bn> and<bn> she's gonna<bn> <br> come<bn> tomorrow she's gonna come at eleven <pau> yeah <pau> <bn> okay <bn> clean my room <bn> and<bn> then<bn> when<bn> i'm<bn> done<bn> i<bn> get<bn> to<bn> play<bn> with<bn> my<bn> friend<bn> <pau> brittney we go over to her house and we play barbies <pau> and <br> we uhm <pau> we ride our bikes after we're done and then we eat some ice cream <pau> i have four sisters <pau> <bs> one's fifteen <bn> th* four* thirteen <br> and ten and one's five <pau> yeah <pau> <bn> they're nice and they let me <br> uhm watch tv<ln> in their room <bs> and uhm <br> <pau> and<bn> <br> she<bn> when sometimes<ln> when i <br> do a little bit of chores <br> she gives me a dollar\n",
      "{'text': ' a b c d e f g h i j k l m n o p q r s t u v w x y and z my family she went to go pick up my little sister and shes gonna come tomorrow shes gonna come at eleven yeah okay clean my room and then when im done i get to play with my friend brittany we go over to her house and we play barbies and we uhm we ride our bikes after were done and then we eat some ice cream i have four sisters ones fifteen thirteen and ten and ones five yeah theyre nice and they let me uhm watch tv in their room and uhm and she when sometimes when i do a little bit of chores she gives me a dollar'}\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "sample = dss[\"cslu\"][0][\"audio\"]\n",
    "\n",
    "result = pipe(sample)\n",
    "print(dss[\"cslu\"][0][\"sentence\"])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65961980-2890-4bb0-9df3-f01669a670a1",
   "metadata": {},
   "source": [
    "# Run on original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdea92fc-909d-4c69-b014-26b086571e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pipe(dss[\"cslu\"][\"audio\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eba6ac97-e7dc-45e1-8c89-bf03f2a3afd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = BasicTextNormalizer()\n",
    "\n",
    "\n",
    "def normalize_transcript(text):\n",
    "    # The original transcript has annotations, for example a pause is <pau>\n",
    "    # Remove tags in angle brackets\n",
    "    text = re.sub(r\"<[^>]*>\", \"\", text)\n",
    "\n",
    "    # These are \"false starts\" in the original transcript, for example th*\n",
    "    # These are ignored by ASR\n",
    "    # Remove words that end with asterisks (e.g., th*)\n",
    "    text = re.sub(r\"\\S*\\*\", \"\", text)\n",
    "\n",
    "    # Apply Whisper's English normalizer\n",
    "    normalized_text = normalizer(text)\n",
    "\n",
    "    return normalized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73e7f201-c0ed-49a2-9a71-39405cdbd72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'wer': 0.15899313905005624}\n"
     ]
    }
   ],
   "source": [
    "def weighted_wer(ref: list[str], pred: list[str]):\n",
    "    # Normalize both predictions and references\n",
    "    pred_normalized = [normalize_transcript(text) for text in pred]\n",
    "    label_normalized = [normalize_transcript(text) for text in ref]\n",
    "\n",
    "    total_errors = 0\n",
    "    total_words = 0\n",
    "\n",
    "    for pred_text, ref_text in zip(pred_normalized, label_normalized):\n",
    "        ref_words = ref_text.split()\n",
    "\n",
    "        # Compute WER for this sample\n",
    "        sample_wer = jiwer.wer(ref_text, pred_text)\n",
    "\n",
    "        # Accumulate weighted errors\n",
    "        sample_errors = sample_wer * len(ref_words)\n",
    "        total_errors += sample_errors\n",
    "        total_words += len(ref_words)\n",
    "\n",
    "    weighted_wer = total_errors / total_words if total_words > 0 else 0.0\n",
    "\n",
    "    return {\"wer\": weighted_wer}\n",
    "\n",
    "\n",
    "predictions = [d[\"text\"] for d in results]\n",
    "references = dss[\"cslu\"][\"sentence\"]\n",
    "wer_score = weighted_wer(references, predictions)\n",
    "print(wer_score)  # {'wer': 0.15899313905005624} on 07-08-25"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hf]",
   "language": "python",
   "name": "conda-env-hf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
